{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1941365,"sourceType":"datasetVersion","datasetId":1158033}],"dockerImageVersionId":30096,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.patches as patches\nimport pylab as pl\nfrom PIL import Image\nimport cv2\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = \"../input/medical-face-mask-detection-dataset/withMaskDataset/withMaskDataset/DNU016CWPZOGFRK5YA3X.jpg\"\n_ = plt.figure(figsize = (15,20))\n_ = plt.axis('off')\n_ = plt.imshow(mpimg.imread(img))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading color image\nmask = cv2.imread('/kaggle/input/medical-face-mask-detection-dataset/withMaskDataset/withMaskDataset/DNU016CWPZOGFRK5YA3X.jpg')\nplt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The shape of image is ', mask.shape)","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Plotting the RGB channels of the image","metadata":{}},{"cell_type":"code","source":"mask_r  = cv2.imread('/kaggle/input/medical-face-mask-detection-dataset/withMaskDataset/withMaskDataset/DNU016CWPZOGFRK5YA3X.jpg')\nmask_r[:,:,1:2] = 0\nplt.imshow(mask_r)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_g  = cv2.imread('/kaggle/input/medical-face-mask-detection-dataset/withMaskDataset/withMaskDataset/DNU016CWPZOGFRK5YA3X.jpg')\nmask_g[:,:,(0,2)] = 0\nplt.imshow(mask_g)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_b  = cv2.imread('/kaggle/input/medical-face-mask-detection-dataset/withMaskDataset/withMaskDataset/DNU016CWPZOGFRK5YA3X.jpg')\nmask_b[:,:,0:1] = 0\nplt.imshow(mask_b)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Code by Brad Lee https://www.kaggle.com/kairess/garbage-classification","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\nfrom keras.models import Sequential\n\nimport glob, os, random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove one withMaskDataset from path (file) to avoid an empty list\n\nbase_path = '../input/medical-face-mask-detection-dataset/withMaskDataset/'\n\nimg_list = glob.glob(os.path.join(base_path, '*/*.jpg'))\n\nprint(len(img_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, img_path in enumerate(random.sample(img_list, 6)):\n    img = load_img(img_path)\n    img = img_to_array(img, dtype=np.uint8)\n\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img.squeeze())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.1\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    base_path,\n    target_size=(300, 300),\n    batch_size=16,\n    class_mode='categorical',\n    subset='training',\n    seed=0\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    base_path,\n    target_size=(300, 300),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation',\n    seed=0\n)\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\nprint(labels)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#The original code (above) has 6 classes (garbage: glass, metal, paper, plastic, trash). Mine found \n\n#only 1(One) class and that will prevent me to perform the last snippet.","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),\n    MaxPooling2D(pool_size=2),\n\n    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n\n    Flatten(),\n\n    Dense(64, activation='relu'),\n\n    Dense(6, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Take a Shot??","metadata":{}},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Another Shot??","metadata":{}},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Why more shots? The author didn't explain it.","metadata":{}},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x, test_y = validation_generator.__getitem__(1)\n\npreds = model.predict(test_x)\n\nplt.figure(figsize=(16, 16))\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n   # plt.title('pred:%s / truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))\n    plt.imshow(test_x[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#I commented plt.title above since I got Key error: 2 or 1. I hope it will work. Inside I had images \n\n#not classified (preds). I think I got that error since the images belong to only 1 class as I wrote\n\n#six snippets above. I'll find out if it has worked only when all that shots have finished to run.","metadata":{}},{"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Thank you Brad Lee @kairess for the script')","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]}]}